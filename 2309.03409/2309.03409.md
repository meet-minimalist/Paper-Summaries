# Large Language Models as Optimizers

**Authors:** Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V. Le, Denny Zhou, Xinyun Chen

**arXiv ID:** 2309.03409

**Published:** September 7, 2023

**Link:** https://arxiv.org/abs/2309.03409

---

## Core Contribution

This paper introduces **OPRO (Optimization by PROmpting)**, a novel method that enables large language models (LLMs) to perform optimization tasks without requiring gradients. The key innovation is formulating optimization problems in natural language and using LLMs to iteratively generate and refine solutions through prompted generation and evaluation.

OPRO addresses the fundamental challenge of optimization in settings where derivative-based algorithms cannot be applied, opening new possibilities for LLM-driven solutions across various real-world applications.

---

## Technical Approach

**OPRO Framework:**

The optimization process works through iterative prompting:

1. **Prompt Structure:** The prompt contains previously generated solutions along with their evaluated performance values
2. **Solution Generation:** The LLM generates new candidate solutions based on the prompt context
3. **Evaluation:** New solutions are evaluated on the target objective function
4. **Iteration:** The best-performing solutions are added back to the prompt for the next optimization step

**Key Design Elements:**

- **Natural Language Formulation:** Optimization tasks are described in plain language, making them accessible to LLMs
- **In-Context Learning:** The LLM learns from the history of solutions and their values within the prompt
- **Gradient-Free:** No derivative information required, enabling optimization in black-box settings

**Applications Demonstrated:**

- Linear regression problems
- Traveling salesman problems (TSP)
- **Primary Focus:** Prompt optimization for maximizing task accuracy

---

## Key Results & Ablations

**Prompt Optimization Performance:**

- **GSM8K Dataset:** OPRO-optimized prompts outperform human-designed prompts by **up to 8%**
- **Big-Bench Hard Tasks:** Improvements of **up to 50%** over human-designed prompts
- Tested across multiple LLM architectures, demonstrating robustness

**Key Findings:**

- LLMs can effectively explore solution spaces through iterative prompting
- Performance improves as more solution-value pairs are added to the prompt context
- The approach generalizes across different types of optimization problems
- Different LLMs show varying optimization capabilities, but all demonstrate improvement over baselines

**Ablation Studies:**

- Impact of prompt history length on optimization quality
- Comparison of different LLM sizes and architectures
- Analysis of convergence behavior across problem types

---

## Important Citations & Related Work

**Related Areas:**

- **Gradient-Based Optimization:** Traditional methods that require differentiability
- **Black-Box Optimization:** Evolutionary algorithms, Bayesian optimization, and other gradient-free methods
- **Prompt Engineering:** Manual design of prompts for LLM tasks
- **In-Context Learning:** LLMs' ability to learn from examples in prompts
- **Meta-Learning:** Learning to learn and optimization of learning algorithms

**Key Distinctions:**

OPRO differs from traditional optimization by leveraging natural language as the optimization interface and using LLMs' reasoning capabilities rather than mathematical gradient computation.

---

## Conclusion & Impact

**Significance:**

OPRO represents a paradigm shift in optimization, demonstrating that LLMs can serve as general-purpose optimizers through natural language interaction. This has profound implications:

1. **Accessibility:** Makes optimization accessible in domains where gradients are unavailable or difficult to compute
2. **Prompt Engineering:** Automates the labor-intensive process of manual prompt design
3. **Broader Applications:** Opens possibilities for LLM-driven optimization in diverse fields including hyperparameter tuning, algorithm design, and creative problem-solving

**Future Directions:**

- Scaling to more complex optimization landscapes
- Combining OPRO with traditional optimization methods
- Exploring multi-objective optimization scenarios
- Application to real-world industrial problems

**Code Availability:** https://github.com/google-deepmind/opro

The work establishes LLMs as viable optimization tools, potentially transforming how we approach optimization problems in the era of large language models.

---

*Summary generated on: 2025-11-20*